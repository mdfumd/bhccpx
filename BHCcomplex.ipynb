{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Legal Notice\n",
    "<span style=\"font-family: 'Monospace'; font-size: 0.6em;\">\n",
    "The BHC Complexity Toolkit is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\n",
    "<br/>\n",
    "The BHC Complexity Toolkit is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.\n",
    "<br/>\n",
    "You should have received a copy of the GNU General Public License along with the BHC Complexity Toolkit.  If not, see <https://www.gnu.org/licenses/>.\n",
    "<br/><br/>\n",
    "Copyright 2019, Mark D. Flood\n",
    "<br/>\n",
    "Author: Mark D. Flood\n",
    "<br/>\n",
    "Last revision: 22-Jun-2019\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Holding Company (BHC) organizational complexity \n",
    "This notebook presents Python source code implementing a method for analyzing the topological complexity of BHC ownership and control hierarchies. Each BHC hierarchy has the structure of a [directed graph](https://en.wikipedia.org/wiki/Directed_graph), where: \n",
    "\n",
    " *   _Nodes_ represent BHC legal entities and their subsidiary firms, and \n",
    " *   _Edges_ represent ownership/control relationships among the nodes\n",
    "\n",
    "Each edge is directed _from_ the controlling firm (the \"parent\") _to_ the subsidiary (\"offspring\") firm. \n",
    "\n",
    "## Data\n",
    "The _Federal Reserve_ collects, via its form FR Y-10, the input data required to implement this methodology:\n",
    "\n",
    " *   Form FR Y-10: [**Report of Changes in Organizational Structure**](https://www.federalreserve.gov/apps/reportforms/reportdetail.aspx?sOoYJ+5BzDaGhRRQo6EFJQ==)\n",
    " \n",
    "     _This report provides data on organizational structural changes for the reportable companies listed in the respondent panel section below. There are eight schedules: Banking; Savings and Loan; Nonbanking; Merger; 4(k); Domestic Branch; Foreign Branches of U.S. Banking Organizations; and Branch, Agency, and Representative Office._\n",
    "     \n",
    "The data form the core of the _Federal Reserve's_ National Information Center (NIC) database. The interagency _Federal Financial Institutions Examination Council_ (FFIEC) makes the NIC data available via their [**NIC Public Website** (NPW)](https://www.ffiec.gov/npw):\n",
    "\n",
    " *   NIC National Information Center: [**Data Download**](https://www.ffiec.gov/npw/FinancialReport/DataDownload)\n",
    " \n",
    "     _Tables of structure information for select banks and institutions for which the Federal Reserve has a supervisory, regulatory, or research interest_\n",
    "\n",
    "The Python code assumes you have downloaded the (zipped) XML version of five files:\n",
    "\n",
    " *   **Attributes - Active**\n",
    " *   **Attributes - Branches**\n",
    " *   **Attributes - Closed**\n",
    " *   **Relationships**\n",
    " *   **Transformations**\n",
    "\n",
    "You should download all five files to capture an internally consistent snapshot of the data at a point in time. The FFIEC updates the data at least quarterly. \n",
    "\n",
    "The FFIEC now ([since 2018](https://www.ffiec.gov/npw/Home/About)) also provides these files in comma-separated-value (CSV) format; the earlier version of the NPW provided XML only. If you choose to download the CSV files instead of XML, then you should skip Step 2 below. \n",
    "\n",
    "The data dictionary describing the NIC dataset (version 2.0, dated July 2018) is available here:\n",
    "\n",
    " *   [**Bulk Data Download - Data Dictionary and Reference Guide**](https://www.ffiec.gov/npw/StaticData/DataDownload/NPW%20Data%20Dictionary.pdf)\n",
    " \n",
    "     _The Bulk Data Download feature was developed in response to growing demand from the public for data in bulk format. Data being provided are considered non-confidential, public data. As our first iteration of this feature, we are releasing the tables related to attributes, relationships,and transformations. Details of these tables can be found in the subsequent sections of this Data Dictionary._\n",
    "     \n",
    "## Mathematical details of complexity measurement\n",
    "The formal methodology implemented by the Python modules is described in detail in the following paper:\n",
    "\n",
    " *   M. Flood, D. Kenett, R. Lumsdaine, and J. Simon (2017), \"The Complexity of Bank Holding Companies: A Topological Approach,\" [Working Paper 23755](http://www.nber.org/papers/w23755), _National Bureau of Economic Research_, August. \n",
    " \n",
    "     _Large bank holding companies (BHCs) are structured into intricate ownership hierarchies involving hundreds or even thousands of legal entities. Each subsidiary in these hierarchies has its own legal form, assets, liabilities, managerial goals, and supervisory authorities. In the event of BHC default or insolvency, regulators may need to resolve the BHC and its constituent entities. Each entity individually will require some mix of cash infusion, outside purchase, consolidation with other subsidiaries, legal guarantees, and outright dissolution. The subsidiaries are not resolved in isolation, of course, but in the context of resolving the consolidated BHC at the top of the hierarchy. The number, diversity, and distribution of subsidiaries within the hierarchy can therefore significantly ease or complicate the resolution process. We propose a set of related metrics intended to assess the complexity of the BHC ownership graph. These proposed metrics focus on the graph quotient relative to certain well identified partitions on the set of subsidiaries, such as charter type and regulatory jurisdiction. The intended measures are mathematically grounded, intuitively sensible, and easy to implement. We illustrate the process with a case study of one large U.S. BHC._\n",
    "     \n",
    "An alternate version of this paper is available from the Office of Financial Research:\n",
    "\n",
    " *   M. Flood, D. Kenett, R. Lumsdaine, and J. Simon (2017), \"The Complexity of Bank Holding Companies: A New Measurement Approach,\" [OFR Working Paper 17-03](https://www.financialresearch.gov/working-papers/2017/09/29/complexity-of-bank-holding-companies/), _Office of Financial Research_, September. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software\n",
    "\n",
    "### Setup\n",
    "\n",
    "The software consists of a set of Python modules, designed to run in the following sequence:\n",
    "\n",
    " 1.   \\[**zip2xml**\\] Unpacking the _National Information Center_ (NIC) data to reveal the raw XML\n",
    " 1.   \\[**xml2csv**\\] Parsing the XML files to create CSV versions of the same data\n",
    " 1.   \\[**csv2sys**\\] Assembling a network (graph) representation of the banking system\n",
    " 1.   \\[**sys2bhc**\\] Extracting individual BHC subgraphs from the system\n",
    " 1.   \\[**bhc2out**\\] Calculating a range of complexity metrics on individual BHC graphs\n",
    " \n",
    "For example, the module **zip2xml.py** contains the code needed to unpack the NIC downloads (a set of \\*.zip files) into the underlying \\*.xml files. \n",
    "\n",
    "This sequence is encoded in the notebook cells below, with each cell invoking one of the Python modules indicated in square brackets above. You can execute the modules in any of several alternative modes:\n",
    "\n",
    " *   Through the steps (cells) in this notebook\n",
    " *   By invoking the modules from the command line\n",
    " *   By running the modules in an interactive Python shell\n",
    " \n",
    "The mode of execution should not affect the outcome of the calculations. \n",
    "\n",
    " *   [Python 3](https://www.python.org/downloads/)\n",
    " *   [Installing Python](https://docs.python-guide.org/starting/installation/)\n",
    "\n",
    "### Dependencies\n",
    "The software requires Python version 3.x to run correctly. \n",
    "\n",
    "In addition, the sofware uses the following supplementary modules:\n",
    "\n",
    " *   tqdm -- v4.0 or higher\n",
    " *   networkx -- v2.2 or higher\n",
    " *   numpy -- v1.15 or higher\n",
    " *   pandas -- v0.22 or higher\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution sequence\n",
    "\n",
    "### Step 0 - Configuration\n",
    "You can control the execution process through a collection of configuration parameters. These parameters reside in the **bhc_complex.ini** configuration file, as key-value pairs. The availability of configuration parameters should discourage tinkering with the (tested) Python code. \n",
    "\n",
    "The configuration file is divided into _sections_, indicated by labels in square brackets. For example, this snippet shows the beginning of the **[DEFAULT]** section in the configuration file:\n",
    "\n",
    "   ***\n",
    "```python\n",
    "# =============================================================================\n",
    "# ====== Default configuration parameters, for all modules ====================\n",
    "# =============================================================================\n",
    "[DEFAULT]\n",
    "\n",
    "# Default verbosity level\n",
    "verbose=True\n",
    "\n",
    "# Default high verbosity level\n",
    "veryverbose=False\n",
    "```\n",
    "   ***\n",
    "\n",
    "All parameter values in the **bhc_complex.ini** file are treated as strings. For simple (one-line) parameter settings, no quotes are required. For example, in the preceding snippet, the **verbose** parameter is assigned the string value, '_True_'. The Python program converts this string into the equivalent boolean value at runtime. \n",
    "\n",
    "Lists and dictionaries in the **bhc_complex.ini** file are handled slightly differently. First, these parameter values are typically read from multiple consecutive lines in the configuration file. The closing brace indicating the end of the list or dictionary must be indented by at least one character (if the closing brace is not indented, it will be treated as the start of a new parameter key). The resulting string is evaluated as standard Python. So, string values _within_ lists and dictionaries should be enclosed in quotes. For example, in the following snippet, the **bhclist** parameter is a list of two integers (ID_RSSDs), while **asoflist** is a list of four strings (note the single quotes indicating string values). \n",
    "\n",
    "   ***\n",
    "```python\n",
    "# =============================================================================\n",
    "# ========= Configuration parameters for sys2bhc.py ===========================\n",
    "# =============================================================================\n",
    "[sys2bhc]\n",
    "\n",
    "bhclist=[\n",
    "    1073551, # Wachovia\n",
    "    1120754, # Wells Fargo\n",
    " ]\n",
    " \n",
    "asoflist=[\n",
    "    '2006Q4', \n",
    "    '2008Q3', \n",
    "    '2008Q4', \n",
    "    '2010Q4', \n",
    " ]\n",
    "```\n",
    "   ***\n",
    "\n",
    "You can also override the parameter values in the **bhc_complex.ini** file at runtime by modifying the configuration after you have read it from disk. The configuration indexes the parameters first by _section_ and then by _key_. For example, to tweak the **indir** directory location, you might submit the following code: \n",
    "\n",
    "   ***\n",
    "```python\n",
    "import bhc_datautil as UTIL\n",
    "CONFIG = UTIL.read_bhc_config()\n",
    "CONFIG['zip2xml']['indir']='../../data/2016redo'\n",
    "```\n",
    "   ***\n",
    "Be sure to enclose all (simple) parameter values within quotes when overriding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 0 - Configuration\n",
    "#\n",
    "# The ability to reload modules is useful\n",
    "from importlib import reload\n",
    "\n",
    "# Add the path to Python code for BHC complexity\n",
    "import sys\n",
    "sys.path.append('./bhccpx/bhccpx/')\n",
    "\n",
    "# Base configuration is stored as key-value pairs in the bhc_config.ini file\n",
    "import bhc_util as UTIL\n",
    "CONFIG = UTIL.read_config()\n",
    "\n",
    "# Last-minute overrides choices within CONFIG:\n",
    "#CONFIG['DEFAULT']['datadir']='./data/2016redo'\n",
    "#CONFIG['DEFAULT']['cachedir']='./data/2016redo/cache'\n",
    "\n",
    "#CONFIG['www2dat']['nic_dir']='./data/NIC'\n",
    "#CONFIG['www2dat']['nic_subdir']='2016redo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Downloading the data\n",
    "This step makes local target directories and downloads (into them) the necessary data public websites:\n",
    "\n",
    " * FFIEC National Information Center (NIC) data on BHC hierarchies\n",
    " * FDIC Summary of Deposits (SoD) data on insured depositories and their branches\n",
    " * FDIC Community Banking (CB) data \n",
    " * FDIC bank failure data\n",
    "\n",
    "Note that the FFIEC has not adhered to a fixed naming convention for NIC filenames over time. The names of the downloaded NIC files can vary, depending on the vintage of the download.  \n",
    "\n",
    "You must run **_Step 0_** first, to load the configuration, before running this step. \n",
    "\n",
    "The parameters for this step cover just the source URLs where the data can be found on the Internet, and the target directories and filenames for storing them when downloaded.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1 - Downloading the data\n",
    "#\n",
    "# Downloads necessary banking data from the Internet\n",
    "import www2dat as w2d\n",
    "# Reload the module, just to ensure the notebook kernel has the latest version from disk\n",
    "reload(w2d)\n",
    "\n",
    "# Now, do the actual work:\n",
    "w2d.make_dirs(CONFIG)\n",
    "w2d.download_data(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Unpacking the data downloads\n",
    "This step unpacks the downloaded data files to local CSV files. \n",
    "\n",
    "Note that the FFIEC has not adhered to a fixed naming convention for NIC filenames over time. The names of the downloaded NIC files can vary, depending on the vintage of the download.  \n",
    "\n",
    "You must run **_Step 0_** first, to load the configuration, before running this step. \n",
    "\n",
    "The parameters for this step cover just the source location where the **\\*.zip** files reside, the target location for storing their unpacked contents, and the names of the five **\\*.zip** files themselves.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2 - Unpacking the data downloads\n",
    "#\n",
    "# Unzips NIC downloads to expose XML or CSV files\n",
    "import dat2csv as d2s\n",
    "# Reload the module, just to ensure the notebook kernel has the latest version from disk\n",
    "reload(d2s)\n",
    "\n",
    "# Now, do the actual work:\n",
    "d2s.unzip_data(CONFIG)\n",
    "d2s.parse_nic(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Caching data objects\n",
    "This step parses and caches certain key data objects, to speed subsequent analysis:\n",
    "\n",
    " * Quarterly FFIEC NIC data, parsed into Pandas dataframes\n",
    " * Quarterly snapshots of the banking system graph, as NetworkX digraphs\n",
    " * Annual FDIC SoD data, as Pandas dataframes\n",
    " * Quarterly FDIC CB reference data, as Pandas dataframes\n",
    " \n",
    "You must run **_Step 0_** first, to load the configuration, before running this step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (74 of 74) |########################| Elapsed Time: 0:01:10 Time:  0:01:10\n",
      "100% (74 of 74) |########################| Elapsed Time: 0:00:18 Time:  0:00:18\n",
      "100% (74 of 74) |########################| Elapsed Time: 0:00:17 Time:  0:00:17\n",
      "100% (74 of 74) |########################| Elapsed Time: 0:00:52 Time:  0:00:52\n"
     ]
    }
   ],
   "source": [
    "# STEP 3 - Caching data objects\n",
    "#\n",
    "# Builds and caches local data objects\n",
    "import csv2cch as c2c\n",
    "# Reload the module, just to ensure the notebook kernel has the latest version from disk\n",
    "reload(c2c)\n",
    "\n",
    "# Now, do the actual work:\n",
    "c2c.build_nic(CONFIG)\n",
    "c2c.build_banksys(CONFIG)\n",
    "c2c.build_fdicsod(CONFIG)\n",
    "c2c.build_fdiccb(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Build banking system network snapshots\n",
    "This step creates network objects representing quarterly snapshots of the banking system. Each quarterly network derives only from the NIC **Relationships** table, so they do not (at this stage) incorporate the attributes describing each node in the network. \n",
    "\n",
    "Two parameters, **asofdate0** and **asofdate1** control the start and end of the quarterly sample, respectively. These parameters are strings of the form _yyyyQn_, where _yyyy_ represents the year and _n_ represents the calendar quarter (1-4).  \n",
    "\n",
    "The network objects are pickled and cached in the output directory, **outdir**. To speed performance, this step checks whether a cached **\\*.pik** file exists before creating a new network object. To override this behavior, ensure that the **clearcache** parameter is set to _True_; this will force the deletion (and recreation) of cached network object for the selected quarters. \n",
    "\n",
    "The **parallel** parameter toggles whether to exploit multiple CPU cores to speed the process. If the parameter is zero (or negative), then snapshots are processed sequentially; otherwise parallelization is active, up to a maximum number of processes given by this parameter. By default, this parameter takes the value of **CONFIG\\['DEFAULT'\\]['parallelcores']**. \n",
    "\n",
    "You must run **_Step 0_** first, to load the configuration, before running this step. \n",
    "\n",
    "The parameters for this step cover the name of the **\\*.csv** relationships file, file locations for the input and the cache, the quarterly start and end dates to process, and whether or not to rebuild the cache.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# STEP 3 - Build banking system network snapshots\n",
    "#\n",
    "# Creates bare network objects for the full banking system at each quarter in a range\n",
    "import csv2sys as c2s\n",
    "# Reload the module, just to ensure the notebook kernel has the latest version from disk\n",
    "reload(c2s)\n",
    "\n",
    "# Some configuration overrides:\n",
    "CONFIG['csv2sys']['attributesactive']='20160630_ATTRIBUTES_ACTIVE.csv'\n",
    "CONFIG['csv2sys']['attributesbranch']='20160630_ATTRIBUTES_BRANCH.csv'\n",
    "CONFIG['csv2sys']['attributesclosed']='20160630_ATTRIBUTES_INACTIVE.csv'\n",
    "CONFIG['csv2sys']['relationships']='20160630_RELATIONSHIPS.csv'\n",
    "#CONFIG['csv2sys']['asofdate0']='2007Q1'\n",
    "CONFIG['csv2sys']['asofdate1']='2016Q2'\n",
    "\n",
    "# Now, do the actual work:\n",
    "c2s.build_sys(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Build individual BHC network snapshots\n",
    "This step creates (and caches) network objects for quarterly snapshots of individual BHCs. Each quarterly BHC network snapshot derives from the NIC **Relationships** table, adding details from the various **Attributes** tables. \n",
    "\n",
    "It is prohibitive to cache a snapshot for every BHC and every quarter in the sample (there are thousands of BHCs and scores of quarters, implying millions of BHC-quarter caches).  The parameters **asoflist** and **bhclist** control the composition of the sample. The **asoflist** parameter contains strings of the form _yyyyQn_, where _yyyy_ represents the year and _n_ represents the calendar quarter (1-4).  The **bhclist** parameter contains integers for the RSSDs (high-holder only) of the BHCs to include. \n",
    "\n",
    "The network objects are pickled and cached in the output directory, **outdir**. To speed performance, this step checks whether a cached **\\*.pik** file exists before creating a new network object. To override this behavior, ensure that the **clearcache** parameter is set to _True_; this will force the deletion (and recreation) of cached network object for the selected quarters. \n",
    "\n",
    "The **parallel** parameter toggles whether to exploit multiple CPU cores to speed the process. If the parameter is zero (or negative), then snapshots are processed sequentially; otherwise parallelization is active, up to a maximum number of processes given by this parameter. By default, this parameter takes the value of **CONFIG\\['DEFAULT'\\]['parallelcores']**. \n",
    "\n",
    "You must run **_Step 0_** first, to load the configuration, before running this step. \n",
    "\n",
    "The parameters for this step cover the name of the **\\*.csv** relationships file, file locations for the input and the cache, the quarterly start and end dates to process, and whether or not to rebuild the cache.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# STEP 4 - Build individual BHC network snapshots\n",
    "#\n",
    "# Creates (and caches) network objects for limited sets of dates and BHCs\n",
    "import csv2sys as c2s\n",
    "import sys2bhc as s2b\n",
    "# Reload the modules, just to ensure the notebook kernel has the latest version from disk\n",
    "reload(c2s)\n",
    "reload(s2b)\n",
    "\n",
    "# Some configuration overrides:\n",
    "CONFIG['sys2bhc']['relationships']='20160630_RELATIONSHIPS.csv'\n",
    "CONFIG['sys2bhc']['attributesactive']='20160630_ATTRIBUTES_ACTIVE.csv'\n",
    "CONFIG['sys2bhc']['attributesbranch']='20160630_ATTRIBUTES_BRANCH.csv'\n",
    "CONFIG['sys2bhc']['attributesclosed']='20160630_ATTRIBUTES_INACTIVE.csv'\n",
    "CONFIG['sys2bhc']['asoflist']='[\"2006Q4\",\"2008Q3\",\"2008Q4\",\"2010Q4\"]'\n",
    "CONFIG['sys2bhc']['bhclist']='[1073551,1120754]'         # RSSDs: 1073551=Wachovia; 1120754=Wells Fargo\n",
    "CONFIG['sys2bhc']['parallel']='0'\n",
    "\n",
    "# Now, do the actual work:\n",
    "s2b.make_bhcs(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Build outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# STEP 5 - Build outputs\n",
    "#\n",
    "# Creates (and caches) network objects for limited sets of dates and BHCs\n",
    "import csv2sys as c2s\n",
    "import sys2bhc as s2b\n",
    "import bhc2out as b2o\n",
    "# Reload the modules, just to ensure the notebook kernel has the latest version from disk\n",
    "reload(c2s)\n",
    "reload(s2b)\n",
    "reload(b2o)\n",
    "\n",
    "# Some configuration overrides:\n",
    "#CONFIG['bhc2out']['parallel']='0'\n",
    "#CONFIG['bhc2out']['make_panel']='False'\n",
    "#CONFIG['DEFAULT']['veryverbose']='True'\n",
    "\n",
    "# Now, do the actual work:\n",
    "UTIL.print_config(CONFIG, 'bhc2out')\n",
    "#b2o.make_panel(CONFIG)\n",
    "b2o.make_wachwells_comparison(CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
