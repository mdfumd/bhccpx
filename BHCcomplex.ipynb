{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Legal Notice\n",
    "<span style=\"font-family: 'Monospace'; font-size: 0.6em;\">\n",
    "The BHC Complexity Toolkit is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\n",
    "<br/>\n",
    "The BHC Complexity Toolkit is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.\n",
    "<br/>\n",
    "You should have received a copy of the GNU General Public License along with the BHC Complexity Toolkit.  If not, see <https://www.gnu.org/licenses/>.\n",
    "<br/><br/>\n",
    "Copyright 2019, Mark D. Flood\n",
    "<br/>\n",
    "Author: Mark D. Flood\n",
    "<br/>\n",
    "Last revision: 22-Jun-2019\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Holding Company (BHC) organizational complexity \n",
    "This notebook presents Python source code implementing a method for analyzing the topological complexity of BHC ownership and control hierarchies. Each BHC hierarchy has the structure of a [directed graph](https://en.wikipedia.org/wiki/Directed_graph), where: \n",
    "\n",
    " *   _Nodes_ represent BHC legal entities and their subsidiary firms, and \n",
    " *   _Edges_ represent ownership/control relationships among the nodes\n",
    "\n",
    "Each edge is directed _from_ the controlling firm (the \"parent\") _to_ the subsidiary (\"offspring\") firm. \n",
    "\n",
    "## Data\n",
    "The _Federal Reserve_ collects, via its form FR Y-10, the input data required to implement this methodology:\n",
    "\n",
    " *   Form FR Y-10: [**Report of Changes in Organizational Structure**](https://www.federalreserve.gov/apps/reportforms/reportdetail.aspx?sOoYJ+5BzDaGhRRQo6EFJQ==)\n",
    " \n",
    "     _This report provides data on organizational structural changes for the reportable companies listed in the respondent panel section below. There are eight schedules: Banking; Savings and Loan; Nonbanking; Merger; 4(k); Domestic Branch; Foreign Branches of U.S. Banking Organizations; and Branch, Agency, and Representative Office._\n",
    "     \n",
    "The data form the core of the _Federal Reserve's_ National Information Center (NIC) database. The interagency _Federal Financial Institutions Examination Council_ (FFIEC) makes the NIC data available via their [**NIC Public Website** (NPW)](https://www.ffiec.gov/npw):\n",
    "\n",
    " *   NIC National Information Center: [**Data Download**](https://www.ffiec.gov/npw/FinancialReport/DataDownload)\n",
    " \n",
    "     _Tables of structure information for select banks and institutions for which the Federal Reserve has a supervisory, regulatory, or research interest_\n",
    "\n",
    "The Python code assumes you have downloaded the (zipped) XML version of five files:\n",
    "\n",
    " *   **Attributes - Active**\n",
    " *   **Attributes - Branches**\n",
    " *   **Attributes - Closed**\n",
    " *   **Relationships**\n",
    " *   **Transformations**\n",
    "\n",
    "You should download all five files to capture an internally consistent snapshot of the data at a point in time. The FFIEC updates the data at least quarterly. \n",
    "\n",
    "The FFIEC now ([since 2018](https://www.ffiec.gov/npw/Home/About)) also provides these files in comma-separated-value (CSV) format; the earlier version of the NPW provided XML only. If you choose to download the CSV files instead of XML, then you should skip Step 2 below. \n",
    "\n",
    "The data dictionary describing the NIC dataset (version 2.0, dated July 2018) is available here:\n",
    "\n",
    " *   [**Bulk Data Download - Data Dictionary and Reference Guide**](https://www.ffiec.gov/npw/StaticData/DataDownload/NPW%20Data%20Dictionary.pdf)\n",
    " \n",
    "     _The Bulk Data Download feature was developed in response to growing demand from the public for data in bulk format. Data being provided are considered non-confidential, public data. As our first iteration of this feature, we are releasing the tables related to attributes, relationships,and transformations. Details of these tables can be found in the subsequent sections of this Data Dictionary._\n",
    "     \n",
    "## Mathematical details of complexity measurement\n",
    "The formal methodology implemented by the Python modules is described in detail in the following paper:\n",
    "\n",
    " *   M. Flood, D. Kenett, R. Lumsdaine, and J. Simon (2017), \"The Complexity of Bank Holding Companies: A Topological Approach,\" [Working Paper 23755](http://www.nber.org/papers/w23755), _National Bureau of Economic Research_, August. \n",
    " \n",
    "     _Large bank holding companies (BHCs) are structured into intricate ownership hierarchies involving hundreds or even thousands of legal entities. Each subsidiary in these hierarchies has its own legal form, assets, liabilities, managerial goals, and supervisory authorities. In the event of BHC default or insolvency, regulators may need to resolve the BHC and its constituent entities. Each entity individually will require some mix of cash infusion, outside purchase, consolidation with other subsidiaries, legal guarantees, and outright dissolution. The subsidiaries are not resolved in isolation, of course, but in the context of resolving the consolidated BHC at the top of the hierarchy. The number, diversity, and distribution of subsidiaries within the hierarchy can therefore significantly ease or complicate the resolution process. We propose a set of related metrics intended to assess the complexity of the BHC ownership graph. These proposed metrics focus on the graph quotient relative to certain well identified partitions on the set of subsidiaries, such as charter type and regulatory jurisdiction. The intended measures are mathematically grounded, intuitively sensible, and easy to implement. We illustrate the process with a case study of one large U.S. BHC._\n",
    "     \n",
    "An alternate version of this paper is available from the Office of Financial Research:\n",
    "\n",
    " *   M. Flood, D. Kenett, R. Lumsdaine, and J. Simon (2017), \"The Complexity of Bank Holding Companies: A New Measurement Approach,\" [OFR Working Paper 17-03](https://www.financialresearch.gov/working-papers/2017/09/29/complexity-of-bank-holding-companies/), _Office of Financial Research_, September. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software\n",
    "\n",
    "### Setup\n",
    "\n",
    "The software is bundled in a Python 3 package, **bhccpx**. The software consists of a set of Python modules, designed to run in the following sequence:\n",
    "\n",
    " 1.   \\[**www2dat**\\] Create local directories and download data from the _National Information Center_ (NIC) site\n",
    " 1.   \\[**dat2csv**\\] Unzipping and parsing (as required) the downloads into CSV versions of the same data\n",
    " 1.   \\[**csv2cch**\\] Creating and caching python data objects from the data\n",
    " 1.   \\[**cch2jbf**\\] Creating various outputs specifically for the J. of Banking and Finance submission\n",
    " \n",
    "This sequence is encoded in the notebook cells below, with each cell invoking one of the Python modules indicated in square brackets above. You can execute the modules in any of several alternative modes:\n",
    "\n",
    " *   Through the steps (cells) in this notebook\n",
    " *   By invoking the modules from the command line\n",
    " *   By running the modules in an interactive Python shell\n",
    " \n",
    "The mode of execution should not affect the outcome of the calculations. \n",
    "\n",
    " *   [Python 3](https://www.python.org/downloads/)\n",
    " *   [Installing Python](https://docs.python-guide.org/starting/installation/)\n",
    "\n",
    "### Dependencies\n",
    "The software requires Python version 3.x to run correctly. \n",
    "\n",
    "In addition, the sofware uses the following supplementary modules:\n",
    "\n",
    " *   networkx -- v2.3 or higher\n",
    " *   numpy -- v1.16 or higher\n",
    " *   pandas -- v0.24 or higher\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution sequence\n",
    "\n",
    "### Step 0 - Configuration\n",
    "You can control the execution process through a collection of configuration parameters. These parameters reside in the **bhc_complex.ini** configuration file, as key-value pairs. The availability of configuration parameters should discourage tinkering with the (tested) Python code. \n",
    "\n",
    "The configuration file is divided into _sections_, indicated by labels in square brackets. For example, this snippet shows the beginning of the **[DEFAULT]** section in the configuration file:\n",
    "\n",
    "   ***\n",
    "```python\n",
    "# =============================================================================\n",
    "# ====== Default configuration parameters, for all modules ====================\n",
    "# =============================================================================\n",
    "[DEFAULT]\n",
    "\n",
    "# Default verbosity level\n",
    "verbose=True\n",
    "\n",
    "# Default high verbosity level\n",
    "veryverbose=False\n",
    "```\n",
    "   ***\n",
    "\n",
    "All parameter values in the **bhc_complex.ini** file are treated as strings. For simple (one-line) parameter settings, no quotes are required. For example, in the preceding snippet, the **verbose** parameter is assigned the string value, '_True_'. The Python program converts this string into the equivalent boolean value at runtime. \n",
    "\n",
    "Lists and dictionaries in the **bhc_complex.ini** file are handled slightly differently. First, these parameter values are typically read from multiple consecutive lines in the configuration file. The closing brace indicating the end of the list or dictionary must be indented by at least one character (if the closing brace is not indented, it will be treated as the start of a new parameter key). The resulting string is evaluated as standard Python. So, string values _within_ lists and dictionaries should be enclosed in quotes. For example, in the following snippet, the **bhclist** parameter is a list of two integers (ID_RSSDs), while **asoflist** is a list of four strings (note the single quotes indicating string values). \n",
    "\n",
    "   ***\n",
    "```python\n",
    "# =============================================================================\n",
    "# ========= Configuration parameters for sys2bhc.py ===========================\n",
    "# =============================================================================\n",
    "[sys2bhc]\n",
    "\n",
    "bhclist=[\n",
    "    1073551, # Wachovia\n",
    "    1120754, # Wells Fargo\n",
    " ]\n",
    " \n",
    "asoflist=[\n",
    "    '2006Q4', \n",
    "    '2008Q3', \n",
    "    '2008Q4', \n",
    "    '2010Q4', \n",
    " ]\n",
    "```\n",
    "   ***\n",
    "\n",
    "You can also override the parameter values in the **bhc_complex.ini** file at runtime by modifying the configuration after you have read it from disk. The configuration indexes the parameters first by _section_ and then by _key_. For example, to tweak the **indir** directory location, you might submit the following code: \n",
    "\n",
    "   ***\n",
    "```python\n",
    "import bhc_datautil as UTIL\n",
    "CONFIG = UTIL.read_bhc_config()\n",
    "CONFIG['zip2xml']['indir']='../../data/2016redo'\n",
    "```\n",
    "   ***\n",
    "Be sure to enclose all (simple) parameter values within quotes when overriding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 0 - Configuration\n",
    "#\n",
    "# The ability to reload modules is useful\n",
    "from importlib import reload\n",
    "\n",
    "# Add the path to Python code for BHC complexity\n",
    "import sys\n",
    "sys.path.append('./bhccpx/bhccpx/')\n",
    "\n",
    "# Base configuration is stored as key-value pairs in the bhc_config.ini file\n",
    "import bhc_util as UTIL\n",
    "CONFIG = UTIL.read_config()\n",
    "\n",
    "# Last-minute overrides choices within CONFIG:\n",
    "#CONFIG['DEFAULT']['datadir']='./data/2016redo'\n",
    "#CONFIG['DEFAULT']['cachedir']='./data/2016redo/cache'\n",
    "\n",
    "#CONFIG['www2dat']['nic_dir']='./data/NIC'\n",
    "#CONFIG['www2dat']['nic_subdir']='2016redo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Downloading the data\n",
    "This step makes local target directories and downloads (into them) the necessary data public websites:\n",
    "\n",
    " * FFIEC National Information Center (NIC) data on BHC hierarchies\n",
    " * FDIC Summary of Deposits (SoD) data on insured depositories and their branches\n",
    " * FDIC Community Banking (CB) data \n",
    " * FDIC bank failure data\n",
    "\n",
    "Note that the FFIEC has not adhered to a fixed naming convention for NIC filenames over time. The names of the downloaded NIC files can vary, depending on the vintage of the download.  \n",
    "\n",
    "You must run **_Step 0_** first, to load the configuration, before running this step. \n",
    "\n",
    "The parameters for this step cover just the source URLs where the data can be found on the Internet, and the target directories and filenames for storing them when downloaded.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (25 of 25) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "100% (1 of 1) |##########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "# STEP 1 - Downloading the data\n",
    "#\n",
    "# Downloads necessary banking data from the Internet\n",
    "import www2dat as w2d\n",
    "# Reload the module, just to ensure the notebook kernel has the latest version from disk\n",
    "reload(w2d)\n",
    "\n",
    "# Now, do the actual work:\n",
    "w2d.make_dirs(CONFIG)\n",
    "w2d.download_data(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Unpacking the data downloads\n",
    "This step unpacks the downloaded data files to local CSV files. \n",
    "\n",
    "Note that the FFIEC has not adhered to a fixed naming convention for NIC filenames over time. The names of the downloaded NIC files can vary, depending on the vintage of the download.  \n",
    "\n",
    "You must run **_Step 0_** first, to load the configuration, before running this step. \n",
    "\n",
    "The parameters for this step cover just the source location where the **\\*.zip** files reside, the target location for storing their unpacked contents, and the names of the five **\\*.zip** files themselves.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5 of 5) |##########################| Elapsed Time: 0:00:13 Time:  0:00:13\n",
      "100% (25 of 25) |########################| Elapsed Time: 0:00:14 Time:  0:00:14\n",
      "100% (7 of 7) |##########################| Elapsed Time: 0:00:05 Time:  0:00:05\n",
      "N/A% (0 of 1) |                          | Elapsed Time: 5:12:32 ETA:  --:--:--"
     ]
    }
   ],
   "source": [
    "# STEP 2 - Unpacking the data downloads\n",
    "#\n",
    "# Unzips NIC downloads to expose XML or CSV files\n",
    "import dat2csv as d2s\n",
    "# Reload the module, just to ensure the notebook kernel has the latest version from disk\n",
    "reload(d2s)\n",
    "\n",
    "# Now, do the actual work:\n",
    "d2s.unzip_data(CONFIG)\n",
    "d2s.parse_nic(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Caching data objects\n",
    "This step parses and caches certain key data objects, to speed subsequent analysis:\n",
    "\n",
    " * Quarterly FFIEC NIC data, parsed into Pandas dataframes\n",
    " * Quarterly snapshots of the banking system graph, as NetworkX digraphs\n",
    " * Annual FDIC SoD data, as Pandas dataframes\n",
    " * Quarterly FDIC CB reference data, as Pandas dataframes\n",
    " \n",
    "You must run **_Step 0_** first, to load the configuration, before running this step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# STEP 3 - Caching data objects\n",
    "#\n",
    "# Builds and caches local data objects\n",
    "import csv2cch as c2c\n",
    "# Reload the module, just to ensure the notebook kernel has the latest version from disk\n",
    "reload(c2c)\n",
    "\n",
    "# Now, do the actual work:\n",
    "c2c.build_nic(CONFIG)\n",
    "c2c.build_banksys(CONFIG)\n",
    "c2c.build_fdicsod(CONFIG)\n",
    "c2c.build_fdiccb(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Build journal submission outputs\n",
    "This step creates several outputs used for the journal submission\n",
    "\n",
    "You must run **_Step 0_** first, to load the configuration, before running this step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-64:\n",
      "Process ForkPoolWorker-61:\n",
      "Process ForkPoolWorker-63:\n",
      "Process ForkPoolWorker-65:\n",
      "Process ForkPoolWorker-62:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"./bhccpx/bhccpx/cch2jbf.py\", line 403, in make_panel_asof\n",
      "    #            context = f'ASOF={asofdate}, RSSD={rssd}'\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-cd892e6aa59f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Now, do the actual work:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mc2j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_wachwells\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mc2j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_panel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mc2j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_failscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mc2j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_persistent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mf/Projects/bhc_complex/NewSpace/bhccpx/bhccpx/cch2jbf.py\u001b[0m in \u001b[0;36mmake_panel\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mLOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Parallel processing complete'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mf/Projects/bhc_complex/NewSpace/bhccpx/bhccpx/cch2jbf.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mLOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Parallel processing complete'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"./bhccpx/bhccpx/cch2jbf.py\", line 402, in make_panel_asof\n",
      "    #        if ('TRUE'==config[MODNAME]['test_metrics'].upper()):\n",
      "  File \"./bhccpx/bhccpx/cch2jbf.py\", line 143, in populate_bhc\n",
      "    BHC = c2c.add_attributes_edge(BHC, NICdata, edge_atts)\n",
      "  File \"./bhccpx/bhccpx/csv2cch.py\", line 133, in add_attributes_edge\n",
      "    rel = RELdf.query(f'rssd_par=={par} and rssd_off=={off}').iloc[0]\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/frame.py\", line 3088, in query\n",
      "    res = self.eval(expr, **kwargs)\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/frame.py\", line 3203, in eval\n",
      "    return _eval(expr, inplace=inplace, **kwargs)\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/computation/eval.py\", line 299, in eval\n",
      "    ret = eng_inst.evaluate()\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/computation/engines.py\", line 76, in evaluate\n",
      "    res = self._evaluate()\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/computation/engines.py\", line 123, in _evaluate\n",
      "    return ne.evaluate(s, local_dict=scope, truediv=truediv)\n",
      "  File \"/usr/lib/python3/dist-packages/numexpr/necompiler.py\", line 801, in evaluate\n",
      "    _names_cache[expr_key] = getExprNames(ex, context)\n",
      "  File \"/usr/lib/python3/dist-packages/numexpr/necompiler.py\", line 722, in getExprNames\n",
      "    return [a.value for a in input_order], ex_uses_vml\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/copy.py\", line 263, in _keep_alive\n",
      "    memo[id(memo)].append(x)\n",
      "Traceback (most recent call last):\n",
      "KeyError: 139764416403712\n",
      "Traceback (most recent call last):\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"./bhccpx/bhccpx/cch2jbf.py\", line 403, in make_panel_asof\n",
      "    #            context = f'ASOF={asofdate}, RSSD={rssd}'\n",
      "  File \"./bhccpx/bhccpx/bhca.py\", line 136, in complexity_workup\n",
      "    QGFC = get_quotient(BHC, dimen, Q_FULL_COND)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"./bhccpx/bhccpx/cch2jbf.py\", line 402, in make_panel_asof\n",
      "    #        if ('TRUE'==config[MODNAME]['test_metrics'].upper()):\n",
      "  File \"./bhccpx/bhccpx/cch2jbf.py\", line 402, in make_panel_asof\n",
      "    #        if ('TRUE'==config[MODNAME]['test_metrics'].upper()):\n",
      "  File \"./bhccpx/bhccpx/cch2jbf.py\", line 143, in populate_bhc\n",
      "    BHC = c2c.add_attributes_edge(BHC, NICdata, edge_atts)\n",
      "  File \"./bhccpx/bhccpx/csv2cch.py\", line 133, in add_attributes_edge\n",
      "    rel = RELdf.query(f'rssd_par=={par} and rssd_off=={off}').iloc[0]\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/frame.py\", line 3088, in query\n",
      "    res = self.eval(expr, **kwargs)\n",
      "  File \"./bhccpx/bhccpx/bhca.py\", line 311, in get_quotient\n",
      "    BHCu = BHC.to_undirected()\n",
      "  File \"./bhccpx/bhccpx/cch2jbf.py\", line 143, in populate_bhc\n",
      "    BHC = c2c.add_attributes_edge(BHC, NICdata, edge_atts)\n",
      "  File \"./bhccpx/bhccpx/csv2cch.py\", line 133, in add_attributes_edge\n",
      "    rel = RELdf.query(f'rssd_par=={par} and rssd_off=={off}').iloc[0]\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/frame.py\", line 3088, in query\n",
      "    res = self.eval(expr, **kwargs)\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/frame.py\", line 3198, in eval\n",
      "    index_resolvers = self._get_index_resolvers()\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/networkx/classes/digraph.py\", line 1168, in to_undirected\n",
      "    G.graph.update(deepcopy(self.graph))\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/generic.py\", line 423, in _get_index_resolvers\n",
      "    d.update(self._get_axis_resolvers(axis_name))\n",
      "  File \"/usr/lib/python3.6/copy.py\", line 185, in deepcopy\n",
      "    _keep_alive(x, memo) # Make sure x lives at least as long as d\n",
      "  File \"/usr/lib/python3.6/copy.py\", line 266, in _keep_alive\n",
      "    memo[id(memo)]=[x]\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/generic.py\", line 423, in _get_index_resolvers\n",
      "    d.update(self._get_axis_resolvers(axis_name))\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/frame.py\", line 3198, in eval\n",
      "    index_resolvers = self._get_index_resolvers()\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/generic.py\", line 406, in _get_axis_resolvers\n",
      "    level_values = axis_index.get_level_values(level)\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/generic.py\", line 406, in _get_axis_resolvers\n",
      "    level_values = axis_index.get_level_values(level)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/indexes/multi.py\", line 1413, in get_level_values\n",
      "    values = self._get_level_values(level)\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/indexes/multi.py\", line 1376, in _get_level_values\n",
      "    fill_value=values._na_value)\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/indexes/multi.py\", line 1413, in get_level_values\n",
      "    values = self._get_level_values(level)\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/algorithms.py\", line 1655, in take_nd\n",
      "    func(arr, indexer, out, fill_value)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/indexes/multi.py\", line 1376, in _get_level_values\n",
      "    fill_value=values._na_value)\n",
      "  File \"/home/mf/.local/lib/python3.6/site-packages/pandas/core/algorithms.py\", line 1655, in take_nd\n",
      "    func(arr, indexer, out, fill_value)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# STEP 4 - Build outputs\n",
    "#\n",
    "# Creates (and caches) network objects for limited sets of dates and BHCs\n",
    "import cch2jbf as c2j\n",
    "\n",
    "# Reload the modules, just to ensure the notebook kernel has the latest version from disk\n",
    "reload(c2j)\n",
    "\n",
    "# Now, do the actual work:\n",
    "c2j.make_wachwells(CONFIG)\n",
    "c2j.make_panel(CONFIG)\n",
    "c2j.make_failscatter(CONFIG)\n",
    "c2j.make_persistent(CONFIG)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
